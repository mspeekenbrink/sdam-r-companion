# Moderation and mediation

## Moderation in linear models

Including an interaction in a linear model in R is straightforward. If you have two predictors, `x1` and `x2`, and want to include both the "simple slopes" as well as the slope for the "product predictor" (i.e. `x1` $\times$ `x2`), then the model with `y` as dependent variable can be specified in formula form as

`y ~ x1 * x2`

which evaluates to

`y ~ 1 + x1 + x2 + x1:x2`

As discussed previously, `1` represents the intercept, which is automatically included in a model specification, unless you remove it explicitly by adding `-1` to the formula. `x1` represents the "simple effect" of `x1`, `x2` the corresponding "simple effect" of `x2`, whilst `x1:x2` represents the _product-predictor_ for the interaction between `x1` and `x2` (perhaps a little confusing for those of you who know `:` as a division operator). Because you would generally want to include the simple effects for the predictors as well as the interaction, the authors of R have chosen to save you typing in the full model by expanding `x1 * x2` in this way. This can be used to specify more complicated models, with three-way interactions. For instance,

`y ~ x1 * x2 * x3`

evaluates to

`y ~ 1 + x1 + x2 + x3 + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3`

which is a model with all "simple effects", all pairwise product-predictors, as well as a three-way product predictor which is `x1` $\times$ `x2` $\times$ `x3`. We won't discuss such higher-order interactions until later, but it is good to be aware of this in advance.

As a linear model with a product-predictors is just another linear model, that is really all there is to say about specifying linear models with interactions/moderation in R. Through the formula interface, R will create the necessary additional product predictor(s), and then estimate the parameters of the resulting linear model. 

Let's have a look at how this works with the `speeddate` data which was also analysed in the SDAM book. The data is included in the `sdamr` package, and can be loaded and (partially) inspected as usual:
```{r}
library(sdamr)
data("speeddate")
head(speeddate)
```

There are rather a large number of variables in the dataset. You can obtain more information about each variable in the documentation of the dataset, by calling `?speeddate`. In my humble opinion, the (generally quite) good documentation of R packages is a real benefit of R over some other systems, and I __strongly recommend__ you to check out and read the documentation of functions and datasets before you use them. Functions in R are generally quite flexible and it is infeasible to discuss all the nuances and possibilities in introductory notes like these. In the book, we mainly focused on the variables starting with `other_`, which are the perceptions of the participant by their dating partner. For example, the model
$$\begin{align}
\texttt{like}_i =& \beta_0 + \beta_{\texttt{attr}} \times \texttt{attr}_i + \beta_{\texttt{intel}} \times \texttt{intel}_i + \beta_{\texttt{fun}} \times \texttt{fun}_i \\
&+ \beta_{\texttt{attr} \times \texttt{intel}} \times (\texttt{attr} \times \texttt{intel})_i + \beta_{\texttt{fun} \times \texttt{intel}} \times (\texttt{fun} \times \texttt{intel})_i + \epsilon_i
\end{align}$$
referred to in the SDAM book can be estimated by calling:
```{r}
modg <- lm(other_like ~ other_attr*other_intel + other_fun*other_intel, data=speeddate)
```
Hypothesis tests with the $t$ statistic are obtained as usual though
```{r}
summary(modg)
```
The equivalent tests with the $F$ statistic are easily obtained through
```{r}
car::Anova(modg,type=3)
```

### A reminder about namespaces

In the code above, I'm using `car::` to refer to a function in the `car` package. Technically, a statement like `package_name::` denotes the __namespace__ of the package with the name `package_name` (i.e., `car` in this case). This allows you to use functions from a package without loading the package completely (without loading all the functions of the package in memory). This can be (and often is!) better than first loading the package through e.g. `library(car)` and then calling `Anova`.  The issue is that different packages can use the same name for a function, and when you call a function, it will be the one of the package that was last loaded. When packages use the same name for functions, the function with the same name from a package that was loaded earlier will be "masked" and R will print this as a warning in the R console. For example, if you load the `dplyr` package (a rather useful package for data manipulation, that is a little too much to discuss here in detail), you will see the following warnings:
```{r, warning=TRUE}
library(dplyr)
```
The line `The following objects are masked from 'package:stats'` indicates that the functions `filter` and `lag` are "masked from the `stats` package. Whenever you call these functions, they will be the corresponding functions from the `dplyr` package, and _not_ those from the `stats` package. This does not break the functionality of the packages themselves, as a properly written package that needs the `filter` function from the `stats` package will still use the function from that namespace (package), and not the one from the `dplyr` one. But when _you_ call the a function, R will try find the definition of that function in the _global_ namespace, and the global namespace contains the version of the last provided definition of any R object. Just like you can overwrite an R object by giving it the same name as an already existing r object (as I often do deliberately through e.g. `mod <- lm()`), a function in R is just another object. So if I specify a function like

```{r}
head <- function(x, na.rm = FALSE) {
  return("Where's your head? It's almost Halloween!")
}
```
Then next time I call that function, I will get as a result
```{r}
head(speeddate)
```
and __not__ the result from
```{r, eval=FALSE}
utils::head(speeddate)
```

## Centering

As discussed in the SDAM book, sometimes you might want to center variables by subtracting their (sample) mean from each value. This can be done in a number of ways. You can either create new variables in a dataframe by subtracting the single value obtained through `mean()` from a vector, as in
```{r}
speeddate$other_like_c <- speeddate$other_like - mean(speeddate$other_like, na.rm = TRUE)
```
and then using the new variable `other_like_c` in your `lm` model. Alternatively, you can do by calling the `scale` function. By default, the `scale` function creates $Z$ transformed variables by subtracting the mean and then dividing this mean-deviation by the standard deviation:
$$\text{scale}(Y_i) = \frac{Y_i - \overline{Y}}{S_Y}$$
The `scale` function has three arguments:

- `x`: the variable (or matrix of variables) which you want to scale
- `center`: a logical value indicating whether you want to subtract the mean
- `scale`: a logical value indicating whether you want to divide by the standard deviation

Centering (subtracting the mean, but not dividing by the standard deviation) is thus obtained by calling `scale(x, scale=FALSE)`. Personally, I find calling a function `scale` with argument `scale = FALSE` a little confusing. The `sdamr` package therefore provides the function `center` which is basically just a version of `scale` which by default sets the argument `scale = FALSE`:
```{r, eval=FALSE}
center <- function(x) {
  scale(x, center = TRUE, scale = FALSE)
}
```

Because R is a functional programming language, you can call the `scale` or `center` function directly within the call to the `lm` function. This saves you having to create centered variables in a dataframe first. For instance, if you have loaded the `sdamr` package (or if you ran the code above defining the `center` function), you can obtain the results of the model with centered predictors by calling

```{r}
modg_c <- lm(other_like ~ center(other_attr)*center(other_intel) + center(other_fun)*center(other_intel), data=speeddate)
summary(modg_c)
```

## Mediation analysis

In the SDAM book, we looked at mediation with a different dataset called `legacy2015`. This is also part of the `sdamr` package, and we can make it available and look at the initial cases as usual:

```{r}
data("legacy2015")
head(legacy2015)
```

Oops! We had overwritten ("masked") the `head` function before. We can get rid of our new definition of the `head` function by removing it from the global namespace with the `rm()` function (the name refers to _remove_):
```{r}
rm("head")
```
After this, we can try again:
```{r}
head(legacy2015)
```

### Causal steps

The causal steps approach to assessing mediation is done through testing significance of effects in three regression models. This can be done straightforwardly with the `lm()` function which we have used quite a bit already. For instance, to assess whether the relation between `legacy` and `donation` is mediated by `intention`, we would estimate and test the parameters of the following models: 
```{r}
mod1 <- lm(donation ~ legacy, data = legacy2015)
mod2 <- lm(intention ~ legacy, data = legacy2015)
mod3 <- lm(donation ~ intention + legacy, data = legacy2015)
```

### Investigating the mediated (indirect) effect with a bootstrap test

There are quite a few packages in R which will allow you to test the mediated effect of a predictor on the dependent variable "via" the mediator. I have chosen here for the `mediate` function from the `mediation` package [@R-mediation], as it is a versatile option, and doesn't require too much additional explanation. Another very good option to conduct mediation analysis is to specify the mediation model through a generalization of linear models generally called _Structural Equation Models_. These are multivariate models and something we will cover later on. For present purposes, this can be seen as a way to link different regression models (i.e. the dependent variable of one regression model becomes a predictor in another regression model) into what are conventionally called _path models_. The current "go-to" and most comprehensive SEM package in R is called `lavaan` and we will consider that package in a later chapter.

Let's focus on the `mediation` package for now. If you haven't done so already, you will need to install it with
```{r, eval=FALSE}
install.packages("mediation")
```
If you check the documentation of `mediate` in this package (i.e type `?mediation::mediate`), you will see there are lots of arguments to specify. We will only focus one the ones important for present purposes:

* `model.m`: the name of the R object which contains the linear model predicting the mediator from the predictor, e.g. `mod2` above 
* `model.y`: the name of the R object which contains the linear model predicting the dependent variable from both the mediator and predictor, e.g. `mod3` above 
* `sims`: the number of simulations to use for the bootstrap test
* `boot`: (logical) whether to use a bootstrap test. You should set this to `TRUE`
* `boot.ci.type`: the type of bootstrap confidence interval to be computed. This can either be `perc`, which stands for _percentile_, and is a simple way where the empirical 2.5th and 97.5th percentiles are calculated from the ordered outcomes. This is the option chosen by default. The other option is `bca` which stands for _bias-corrected and accelerated_. This includes a correction of the percentile method to try and reduce bias. It is generally recommended to use this option in mediation analysis. Hence, you should set `boot.ci.type = "bca"`
* `treat`: the name of the predictor in the linear models specified under `model.m` and `model.y`. This is would be e.g. `legacy` in the models above 
* `mediator`: the name of the mediator in the linear models specified under `model.m` and `model.y`. This is would be e.g. `intention` in the models above 

To run a bootstrap mediation test with 2000 simulations, we can run the following command:
```{r, cache = TRUE}
set.seed(20201027)
med <- mediation::mediate(model.m = mod2, model.y = mod3, sims = 2000, boot = TRUE, boot.ci.type = "bca", treat = "legacy", mediator = "intention")
summary(med)
```
Note that rather than loading the `mediation` package with e.g. `library(mediation)` I'm calling the `mediate` function through `mediation::mediate`. Loading the `mediation` package results in loading quite a few other R packages, which are not all necessary to perform a mediation analysis with linear models. Calling the mediate function directly through the appropriate namespace avoids loading these other add-on packages (which then will mask some functions that I don't want masked).

The output from calling the `summary` function on the results of the bootstrap procedure (the R object I named `med`) has four rows:

* `ACME`: this is the _average causal mediation effect_, i.e. the average of $\hat{a} \times \hat{b}$ in the simulations. The value under `estimate` is the average, and you will also see the lower and upper bound of the 95% confidence interval under `95% CI Lower` and `95% CI Upper` respectively. Finally, the `p-value` is the probability of the found `ACME` or more extreme given that in reality, the `ACME` equals 0. I.e., this is the p-value of the hypothesis test that the true mediated effect equals 0.
* `ADE`: this is the _average direct effect_, and reflects the effect of the predictor which is not mediated. It is the average of $\hat{c}'$ in the simulations.  
* `Total Effect` is the total effect of the predictor on the dependent variable, which is the sum of the `ACME` and `ADE`.
* `Prop. Mediated` is the proportion of the effect of the predictor on the dependent variable which is mediated. This is `ACME` divided by `Total Effect`. 

The results under `ACME` show that the bootstrap confidence interval of the mediated effect does not include 0. The p-value for this effect is also smaller than $\alpha = .05$. As such, the null hypothesis that $a \times b = 0$ is rejected, and we have found evidence that the effect of `legacy` on `donation` is mediated by `intention`. Because the confidence interval of the `ADE` also does not include 0, this analysis indicates that the mediation is partial. There is also a significant direct effect of `legacy` on `donation`.  About 33.4% of the effect of `legacy` on `donation` is mediated by `intention`, so the residual direct effect is quite substantial.
